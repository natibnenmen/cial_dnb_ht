# Data Extractor

## Usage
There are two ways to run the script, either running natively on the host, or running a docker container
### Running natively on the host
1. Clone  the following git repo:

    ```git@github.com:natibnenmen/cial_dnb_ht.git```

2. On the root directory, run:

    ```python3 process.py <zip file>```

    Where the ```<zip file>``` is the input zip file which contains the 'debts.txt' input file.

### Running a Docker container
Here again, there are two ways to run the docker image. You can either pull the image from docker hub, or build the image by yourself
1. Pulling the image from docker hub

    Run the following command:

    ```docker run --rm -v <host dir>:<container dir> --name <container name> natibenmen/dnb-data-extractor:1.0 python3 ./process.py <container dir>/<input zip file>```

    Where:

    ```<host dir>``` is a directory on the host which contains the ```<input zip file>```

    ```<container dir>``` is the mount point within the container

    ```<container name>``` is whatever name you give your container

    Please note that ```<container dir>``` should not overwrite ```/opt```, where the process.py script is located.

2. Build the docker image by yourself
    
    * Pull this repository, same as above
    * On the root directory run:

       ``` docker build -t <image name> . ```
    * Run the image, same as when you pull the image from docker hub


## Software structure
### Direcotories, files and configuration
The processor.py is in the repo root dir.
The two configuration files are located at the cfg dir, both were extracted from the data_extractor.zip:
1. ```entity_mapping.tsv``` - was supplied as is

2. ```parsing_config.json``` - created manually based on the data in the ```data_extractor_processing.pdf```

I had two assumptions here:
1. I assume that the both ```entity_mapping.tsv``` and ```data_extractor_processing.pdf``` were supplied as part of the insturctions, and they will not be present in the input zip when the scrit will be run later. So I treated the ```entity_mapping.tsv``` as static configuration. If new configuration will supplied within every input file, the code can easily be adjusted.

2. The input file name within the ```data_extractor_processing.pdf``` is ```data.txt```. In that file it says that the name of the input file in the input zip is ```debts.txt```. I thouth it is a kind of error and my code assume it will only be ```data.txt```.

More assumptions:
3. Although the output example contains no spaces between key and values, I assumes it is not a requirement, so I left a space for readability.
4. When no entity mapping code is found, the 'Unknown' is applied.

### Code
The per line parsing is done by the ```Debt``` class.
The file processing is done by the ```DataProcessor``` class .
For each line, ```DataProcessor``` instnsiates a new ```Debt``` class, and the deleted, to save memory. One can argue about the need to create an instance for each line, saying 
that same instance can process all lines or use a functiona approach, which will save some cpu. However the chosen approach is more modular and still not memory waster.
The configuration is generated by the ```DataProcessor``` and passed to the ```Debt``` constructor. As Python passes function arguments by ref, it is efficient. 
The debts are collected in a dictionary where the key is the ```identification_number``` and the value is a list of ```Debts```. Each ``` debt``` is appended to the list.
The specific output format per the requiremenst is applied on print time.

### Further possible enhancements
1. The list of fields that composes the debt is now hard coded in the ```Debt``` class. This can be configurable to support future requirements.
2. About RAM efficieny. Opening a big file and iteration over its lines is done efficiently by python. The problem is the dictionary which holds the debts. We must keep it till end since any ```identification_number``` can appear till the end.
A possible solution can be to go over the lines, read each ```identification_number``` only and keep a dictionary with ```identification_number``` as key and the value is a list of corresponding lines. The iterate again over the file but now read only the lines per ```identification_number``` each time, parse and print. This will same memory, but will probably have terrible runtime effect.
Another option is to save a ziped ```debt ``` in the dictionary, and then unzip before print. With bad effect on runtime, the save is low since compression is not space efficient on small chunks of data. 
